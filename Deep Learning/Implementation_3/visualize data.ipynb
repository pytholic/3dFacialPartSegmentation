{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3527c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from visualizer.show3d_balls import showpoints\n",
    "import argparse\n",
    "import numpy as np\n",
    "import glob\n",
    "import easydict\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_utils.CustomDataLoader import PartNormalDataset\n",
    "from models import pointnet_part_seg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1885622",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/trojan/skia_projects/3d_facial_segmentation/part_segmentation/pointnet/Pointnet_Pointnet2_pytorch/data/shapenetcore_partanno_segmentation_benchmark_v0_normal/'\n",
    "model_path = './log/part_seg/2021-08-11_14-37/checkpoints/best_model.pth'\n",
    "\n",
    "num_part = 2\n",
    "num_classes = 1\n",
    "seg_classes = {'Head': [0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9489feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'num_point': 2500,\n",
    "                          'normal': False\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c518be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "d = PartNormalDataset(root=root, npoints=args.num_point, split='test', class_choice = ['Head'], normal_channel=args.normal)\n",
    "print(len(d))\n",
    "testDataLoader = torch.utils.data.DataLoader(d, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3882611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_normalize(pc):\n",
    "    centroid = np.mean(pc, axis=0)\n",
    "    pc = pc - centroid\n",
    "    m = np.max(np.sqrt(np.sum(pc ** 2, axis=1)))\n",
    "    pc = pc / m\n",
    "    return pc\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
    "    if (y.is_cuda):\n",
    "        return new_y.cuda()\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d765aa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for pcd in glob.glob(testDir + '/*.txt'):\n",
    "#     data = np.loadtxt(pcd).astype(np.float32)\n",
    "#     point_set = data[:, 0:3]\n",
    "#     point_set = pc_normalize(point_set)\n",
    "#     seg = data[:, -1].astype(np.int32)\n",
    "#     #print(len(point_set), len(seg))\n",
    "    \n",
    "#     cmap = plt.cm.get_cmap(\"hsv\", 10)\n",
    "#     cmap = np.array([cmap(i) for i in range(10)])[:, :3]\n",
    "#     gt = cmap[seg - 1, :]\n",
    "    \n",
    "#     model = args.model\n",
    "#     checkpoint = torch.load(model_path)\n",
    "#     classifier = model.get_model(num_part, normal_channel=normal_channel)\n",
    "#     classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     classifier.eval()\n",
    "    \n",
    "#     for cat in seg_classes.keys():\n",
    "#         for label in seg_classes[cat]:\n",
    "#             seg_label_to_cat[label] = cat\n",
    "                    \n",
    "#     pred, _ = classifier(point_set, to_categorical(label, num_classes))\n",
    "#     pred_choice = pred.data.max(2)[1]\n",
    "#     print(pred_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9436e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for points, label, target in testDataLoader:\n",
    "    print(points.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c436a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4318, -1.0479],\n",
      "         [-0.0471, -3.0788],\n",
      "         [-0.1109, -2.2542],\n",
      "         ...,\n",
      "         [-0.2078, -1.6732],\n",
      "         [-0.0326, -3.4398],\n",
      "         [-0.4144, -1.0810]]], grad_fn=<ViewBackward>)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path)\n",
    "classifier = pointnet_part_seg.get_model(num_part, normal_channel=args.normal)\n",
    "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "classifier.eval()\n",
    "\n",
    "seg_label_to_cat = {}\n",
    "\n",
    "for cat in seg_classes.keys():\n",
    "                for label in seg_classes[cat]:\n",
    "                    seg_label_to_cat[label] = cat\n",
    "                \n",
    "for points, label, target in testDataLoader:\n",
    "    cur_batch_size, NUM_POINT, _ = points.size()\n",
    "    points_np = points.numpy()\n",
    "    \n",
    "    points = points.transpose(2, 1)\n",
    "    \n",
    "    cmap = plt.cm.get_cmap(\"hsv\", 10)\n",
    "    cmap = np.array([cmap(i) for i in range(10)])[:, :3]\n",
    "    gt = cmap[target.numpy() - 1, :]\n",
    "\n",
    "    seg_pred, _ = classifier(points, to_categorical(label, num_classes))\n",
    "    cur_pred_val = seg_pred.cpu().data.numpy()\n",
    "    cur_pred_val_logits = cur_pred_val\n",
    "    cur_pred_val = np.zeros((cur_batch_size, NUM_POINT)).astype(np.int32)\n",
    "    target = target.cpu().data.numpy()\n",
    "    print(seg_pred)\n",
    "    \n",
    "    for i in range(cur_batch_size):\n",
    "        cat = seg_label_to_cat[target[i, 0]]\n",
    "        logits = cur_pred_val_logits[i, :, :]\n",
    "        cur_pred_val[i, :] = np.argmax(logits[:, seg_classes[cat]], 1) + seg_classes[cat][0]\n",
    "    \n",
    "        print(cur_pred_val[i,:])\n",
    "                \n",
    "#     pred_choice = seg_pred.data.max(2)[1]\n",
    "#     print(pred_choice)\n",
    "    \n",
    "#     pred_color = cmap[pred_choice.numpy()[0], :]\n",
    "    \n",
    "    \n",
    "    #showpoints(points_np, gt, pred_color)\n",
    "#     cur_pred_val = seg_pred.cpu().data.numpy()\n",
    "#     cur_pred_val_logits = cur_pred_val\n",
    "#     cur_pred_val = np.zeros((cur_batch_size, NUM_POINT)).astype(np.int32)\n",
    "#     target = target.cpu().data.numpy()\n",
    "    \n",
    "#     for i in range(cur_batch_size):\n",
    "#         cat = seg_label_to_cat[target[i, 0]]\n",
    "#         logits = cur_pred_val_logits[i, :, :]\n",
    "#         cur_pred_val[i, :] = np.argmax(logits[:, seg_classes[cat]], 1) + seg_classes[cat][0]\n",
    "    \n",
    "    \n",
    "#     correct = np.sum(cur_pred_val == target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96927e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/home/trojan/Desktop/pred_choice.txt', pred_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8466abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
