{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a911b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from pointnet.dataset_custom import CustomDataset\n",
    "from pointnet.model import PointNetDenseCls, feature_transform_regularizer\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46515cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({'model': '',\n",
    "                         'batch_size': 4,\n",
    "                         'nepoch': 50,\n",
    "                         'workers': 4,\n",
    "                         'outf': 'seg',\n",
    "                         'dataset': '/home/trojan/skia_projects/3d_facial_segmentation/part_segmentation/pointnet/pointnet.pytorch/datasets/head_data',\n",
    "                         'class_choice': 'Head',\n",
    "                         'feature_transform': True\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fb7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(root = opt.dataset, \n",
    "                        classification=False, \n",
    "                        class_choice=[opt.class_choice])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=opt.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=int(opt.workers))\n",
    "\n",
    "test_dataset = dataset\n",
    "testdataloader = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11557376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "classes 2\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset), len(test_dataset))\n",
    "num_classes = dataset.num_seg_classes\n",
    "print('classes', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a08bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
    "\n",
    "classifier = PointNetDenseCls(k=num_classes, feature_transform=opt.feature_transform)\n",
    "\n",
    "if opt.model != '':\n",
    "    classifier.load_state_dict(torch.load(opt.model))\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "classifier.cuda()\n",
    "\n",
    "num_batch = len(dataset) / opt.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3254a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.3251,  0.1148, -0.3774],\n",
      "         [-0.4508,  0.0981, -0.0861],\n",
      "         [ 0.2302,  0.1945, -0.3538],\n",
      "         ...,\n",
      "         [ 0.2957,  0.1364, -0.3647],\n",
      "         [ 0.1589, -0.5739, -0.5490],\n",
      "         [-0.2575, -0.2002, -0.4415]],\n",
      "\n",
      "        [[-0.2957, -0.3293, -0.4525],\n",
      "         [-0.1520,  0.2354, -0.4684],\n",
      "         [ 0.3153, -0.4257, -0.0979],\n",
      "         ...,\n",
      "         [-0.2795, -0.0797,  0.1173],\n",
      "         [ 0.3072, -0.1062, -0.1866],\n",
      "         [-0.2795,  0.3891,  0.3672]],\n",
      "\n",
      "        [[ 0.1769, -0.5575, -0.2466],\n",
      "         [-0.0084, -0.0269, -0.5778],\n",
      "         [ 0.3709,  0.3471, -0.3778],\n",
      "         ...,\n",
      "         [ 0.6175, -0.1761,  0.0858],\n",
      "         [ 0.4473, -0.3992,  0.2269],\n",
      "         [-0.1526, -0.0619, -0.5297]],\n",
      "\n",
      "        [[-0.3080,  0.5618, -0.0966],\n",
      "         [-0.2153, -0.0689, -0.1576],\n",
      "         [-0.0049,  0.5382,  0.3447],\n",
      "         ...,\n",
      "         [ 0.2446, -0.3441,  0.0678],\n",
      "         [-0.0058,  0.3202,  0.5312],\n",
      "         [-0.3826, -0.3231, -0.2613]]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 0]])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader, 0):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c354ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my target has -1 somewhere which give cuda assert error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d9b130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trojan/anaconda3/envs/pointnet/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0: 0/1] train loss: 0.703526 accuracy: 0.776600\n",
      "[0: 0/1] \u001b[94mtest\u001b[0m loss: 0.655143 accuracy: 0.891700\n",
      "[0: 1/1] train loss: 0.683671 accuracy: 0.580000\n",
      "[1: 0/1] train loss: 0.619542 accuracy: 0.843800\n",
      "[1: 0/1] \u001b[94mtest\u001b[0m loss: 0.650066 accuracy: 0.888600\n",
      "[1: 1/1] train loss: 0.623823 accuracy: 0.647700\n",
      "[2: 0/1] train loss: 0.568924 accuracy: 0.892400\n",
      "[2: 0/1] \u001b[94mtest\u001b[0m loss: 0.595567 accuracy: 0.894000\n",
      "[2: 1/1] train loss: 0.606358 accuracy: 0.655200\n",
      "[3: 0/1] train loss: 0.559753 accuracy: 0.893100\n",
      "[3: 0/1] \u001b[94mtest\u001b[0m loss: 0.557195 accuracy: 0.894600\n",
      "[3: 1/1] train loss: 0.510627 accuracy: 0.678500\n",
      "[4: 0/1] train loss: 0.509494 accuracy: 0.906400\n",
      "[4: 0/1] \u001b[94mtest\u001b[0m loss: 0.512065 accuracy: 0.905400\n",
      "[4: 1/1] train loss: 0.508847 accuracy: 0.664900\n",
      "[5: 0/1] train loss: 0.478209 accuracy: 0.915200\n",
      "[5: 0/1] \u001b[94mtest\u001b[0m loss: 0.462954 accuracy: 0.906900\n",
      "[5: 1/1] train loss: 0.507635 accuracy: 0.659300\n",
      "[6: 0/1] train loss: 0.498200 accuracy: 0.884700\n",
      "[6: 0/1] \u001b[94mtest\u001b[0m loss: 0.434461 accuracy: 0.887400\n",
      "[6: 1/1] train loss: 0.439259 accuracy: 0.686200\n",
      "[7: 0/1] train loss: 0.449757 accuracy: 0.906400\n",
      "[7: 0/1] \u001b[94mtest\u001b[0m loss: 0.418504 accuracy: 0.888000\n",
      "[7: 1/1] train loss: 0.461735 accuracy: 0.666500\n",
      "[8: 0/1] train loss: 0.440529 accuracy: 0.887100\n",
      "[8: 0/1] \u001b[94mtest\u001b[0m loss: 0.412335 accuracy: 0.889700\n",
      "[8: 1/1] train loss: 0.382253 accuracy: 0.686200\n",
      "[9: 0/1] train loss: 0.420989 accuracy: 0.894600\n",
      "[9: 0/1] \u001b[94mtest\u001b[0m loss: 0.399639 accuracy: 0.907100\n",
      "[9: 1/1] train loss: 0.392976 accuracy: 0.678400\n",
      "[10: 0/1] train loss: 0.375438 accuracy: 0.909700\n",
      "[10: 0/1] \u001b[94mtest\u001b[0m loss: 0.355274 accuracy: 0.896500\n",
      "[10: 1/1] train loss: 0.412174 accuracy: 0.664600\n",
      "[11: 0/1] train loss: 0.395244 accuracy: 0.892000\n",
      "[11: 0/1] \u001b[94mtest\u001b[0m loss: 0.363173 accuracy: 0.892800\n",
      "[11: 1/1] train loss: 0.358473 accuracy: 0.682600\n",
      "[12: 0/1] train loss: 0.348597 accuracy: 0.908600\n",
      "[12: 0/1] \u001b[94mtest\u001b[0m loss: 0.412610 accuracy: 0.914900\n",
      "[12: 1/1] train loss: 0.377648 accuracy: 0.664800\n",
      "[13: 0/1] train loss: 0.395032 accuracy: 0.887200\n",
      "[13: 0/1] \u001b[94mtest\u001b[0m loss: 1.067888 accuracy: 0.913800\n",
      "[13: 1/1] train loss: 0.328939 accuracy: 0.685500\n",
      "[14: 0/1] train loss: 0.332362 accuracy: 0.907200\n",
      "[14: 0/1] \u001b[94mtest\u001b[0m loss: 2.343777 accuracy: 0.889400\n",
      "[14: 1/1] train loss: 0.371473 accuracy: 0.667700\n",
      "[15: 0/1] train loss: 0.319209 accuracy: 0.913400\n",
      "[15: 0/1] \u001b[94mtest\u001b[0m loss: 2.368958 accuracy: 0.910300\n",
      "[15: 1/1] train loss: 0.384275 accuracy: 0.660400\n",
      "[16: 0/1] train loss: 0.331733 accuracy: 0.914400\n",
      "[16: 0/1] \u001b[94mtest\u001b[0m loss: 2.110137 accuracy: 0.891600\n",
      "[16: 1/1] train loss: 0.365074 accuracy: 0.658300\n",
      "[17: 0/1] train loss: 0.324638 accuracy: 0.910200\n",
      "[17: 0/1] \u001b[94mtest\u001b[0m loss: 1.955897 accuracy: 0.907400\n",
      "[17: 1/1] train loss: 0.361915 accuracy: 0.664800\n",
      "[18: 0/1] train loss: 0.341143 accuracy: 0.894900\n",
      "[18: 0/1] \u001b[94mtest\u001b[0m loss: 1.722441 accuracy: 0.893300\n",
      "[18: 1/1] train loss: 0.308961 accuracy: 0.679200\n",
      "[19: 0/1] train loss: 0.315278 accuracy: 0.914400\n",
      "[19: 0/1] \u001b[94mtest\u001b[0m loss: 1.249750 accuracy: 0.895200\n",
      "[19: 1/1] train loss: 0.362630 accuracy: 0.660100\n",
      "[20: 0/1] train loss: 0.319508 accuracy: 0.908900\n",
      "[20: 0/1] \u001b[94mtest\u001b[0m loss: 1.012404 accuracy: 0.899000\n",
      "[20: 1/1] train loss: 0.344323 accuracy: 0.666100\n",
      "[21: 0/1] train loss: 0.343659 accuracy: 0.890400\n",
      "[21: 0/1] \u001b[94mtest\u001b[0m loss: 0.722484 accuracy: 0.886200\n",
      "[21: 1/1] train loss: 0.319316 accuracy: 0.686200\n",
      "[22: 0/1] train loss: 0.321758 accuracy: 0.908900\n",
      "[22: 0/1] \u001b[94mtest\u001b[0m loss: 0.433536 accuracy: 0.885000\n",
      "[22: 1/1] train loss: 0.322847 accuracy: 0.664800\n",
      "[23: 0/1] train loss: 0.317395 accuracy: 0.893300\n",
      "[23: 0/1] \u001b[94mtest\u001b[0m loss: 0.346579 accuracy: 0.887800\n",
      "[23: 1/1] train loss: 0.313434 accuracy: 0.680300\n",
      "[24: 0/1] train loss: 0.330309 accuracy: 0.887000\n",
      "[24: 0/1] \u001b[94mtest\u001b[0m loss: 0.333524 accuracy: 0.890100\n",
      "[24: 1/1] train loss: 0.318830 accuracy: 0.687300\n",
      "[25: 0/1] train loss: 0.329199 accuracy: 0.890500\n",
      "[25: 0/1] \u001b[94mtest\u001b[0m loss: 0.380179 accuracy: 0.891500\n",
      "[25: 1/1] train loss: 0.301978 accuracy: 0.687200\n",
      "[26: 0/1] train loss: 0.312641 accuracy: 0.895600\n",
      "[26: 0/1] \u001b[94mtest\u001b[0m loss: 0.343515 accuracy: 0.890700\n",
      "[26: 1/1] train loss: 0.282877 accuracy: 0.680400\n",
      "[27: 0/1] train loss: 0.317555 accuracy: 0.889800\n",
      "[27: 0/1] \u001b[94mtest\u001b[0m loss: 0.316642 accuracy: 0.894900\n",
      "[27: 1/1] train loss: 0.267592 accuracy: 0.685500\n",
      "[28: 0/1] train loss: 0.310398 accuracy: 0.892000\n",
      "[28: 0/1] \u001b[94mtest\u001b[0m loss: 0.277268 accuracy: 0.913700\n",
      "[28: 1/1] train loss: 0.304485 accuracy: 0.683800\n",
      "[29: 0/1] train loss: 0.290518 accuracy: 0.912000\n",
      "[29: 0/1] \u001b[94mtest\u001b[0m loss: 0.284077 accuracy: 0.910300\n",
      "[29: 1/1] train loss: 0.306307 accuracy: 0.662900\n",
      "[30: 0/1] train loss: 0.319868 accuracy: 0.886500\n",
      "[30: 0/1] \u001b[94mtest\u001b[0m loss: 0.291113 accuracy: 0.909900\n",
      "[30: 1/1] train loss: 0.260950 accuracy: 0.686100\n",
      "[31: 0/1] train loss: 0.310739 accuracy: 0.893600\n",
      "[31: 0/1] \u001b[94mtest\u001b[0m loss: 0.294926 accuracy: 0.909800\n",
      "[31: 1/1] train loss: 0.279083 accuracy: 0.682400\n",
      "[32: 0/1] train loss: 0.321547 accuracy: 0.890300\n",
      "[32: 0/1] \u001b[94mtest\u001b[0m loss: 0.322238 accuracy: 0.896800\n",
      "[32: 1/1] train loss: 0.301312 accuracy: 0.686600\n",
      "[33: 0/1] train loss: 0.320860 accuracy: 0.887100\n",
      "[33: 0/1] \u001b[94mtest\u001b[0m loss: 0.294714 accuracy: 0.908600\n",
      "[33: 1/1] train loss: 0.292351 accuracy: 0.685300\n",
      "[34: 0/1] train loss: 0.299173 accuracy: 0.914400\n",
      "[34: 0/1] \u001b[94mtest\u001b[0m loss: 0.291904 accuracy: 0.907100\n",
      "[34: 1/1] train loss: 0.351225 accuracy: 0.659400\n",
      "[35: 0/1] train loss: 0.295157 accuracy: 0.906500\n",
      "[35: 0/1] \u001b[94mtest\u001b[0m loss: 0.332338 accuracy: 0.894900\n",
      "[35: 1/1] train loss: 0.334837 accuracy: 0.667100\n",
      "[36: 0/1] train loss: 0.294802 accuracy: 0.906600\n",
      "[36: 0/1] \u001b[94mtest\u001b[0m loss: 0.294438 accuracy: 0.909100\n",
      "[36: 1/1] train loss: 0.327842 accuracy: 0.668100\n",
      "[37: 0/1] train loss: 0.319231 accuracy: 0.891100\n",
      "[37: 0/1] \u001b[94mtest\u001b[0m loss: 0.350771 accuracy: 0.893500\n",
      "[37: 1/1] train loss: 0.297014 accuracy: 0.682300\n",
      "[38: 0/1] train loss: 0.301657 accuracy: 0.906800\n",
      "[38: 0/1] \u001b[94mtest\u001b[0m loss: 0.291343 accuracy: 0.910400\n",
      "[38: 1/1] train loss: 0.315799 accuracy: 0.665400\n",
      "[39: 0/1] train loss: 0.326569 accuracy: 0.888200\n",
      "[39: 0/1] \u001b[94mtest\u001b[0m loss: 0.269990 accuracy: 0.912300\n",
      "[39: 1/1] train loss: 0.314940 accuracy: 0.686200\n",
      "[40: 0/1] train loss: 0.300271 accuracy: 0.894300\n",
      "[40: 0/1] \u001b[94mtest\u001b[0m loss: 0.296433 accuracy: 0.893600\n",
      "[40: 1/1] train loss: 0.295161 accuracy: 0.677300\n",
      "[41: 0/1] train loss: 0.313665 accuracy: 0.891100\n",
      "[41: 0/1] \u001b[94mtest\u001b[0m loss: 0.313849 accuracy: 0.890400\n",
      "[41: 1/1] train loss: 0.312049 accuracy: 0.667800\n",
      "[42: 0/1] train loss: 0.298269 accuracy: 0.905000\n",
      "[42: 0/1] \u001b[94mtest\u001b[0m loss: 0.263950 accuracy: 0.912100\n",
      "[42: 1/1] train loss: 0.345178 accuracy: 0.666400\n",
      "[43: 0/1] train loss: 0.285067 accuracy: 0.914700\n",
      "[43: 0/1] \u001b[94mtest\u001b[0m loss: 0.273072 accuracy: 0.914400\n",
      "[43: 1/1] train loss: 0.339382 accuracy: 0.657000\n",
      "[44: 0/1] train loss: 0.313223 accuracy: 0.892800\n",
      "[44: 0/1] \u001b[94mtest\u001b[0m loss: 0.272453 accuracy: 0.913500\n",
      "[44: 1/1] train loss: 0.293912 accuracy: 0.678500\n",
      "[45: 0/1] train loss: 0.280882 accuracy: 0.914600\n",
      "[45: 0/1] \u001b[94mtest\u001b[0m loss: 0.315970 accuracy: 0.885000\n",
      "[45: 1/1] train loss: 0.346763 accuracy: 0.658300\n",
      "[46: 0/1] train loss: 0.296357 accuracy: 0.891700\n",
      "[46: 0/1] \u001b[94mtest\u001b[0m loss: 0.289942 accuracy: 0.895000\n",
      "[46: 1/1] train loss: 0.289314 accuracy: 0.683800\n",
      "[47: 0/1] train loss: 0.299775 accuracy: 0.890200\n",
      "[47: 0/1] \u001b[94mtest\u001b[0m loss: 0.283270 accuracy: 0.905400\n",
      "[47: 1/1] train loss: 0.274862 accuracy: 0.681500\n",
      "[48: 0/1] train loss: 0.281034 accuracy: 0.907600\n",
      "[48: 0/1] \u001b[94mtest\u001b[0m loss: 0.305547 accuracy: 0.891700\n",
      "[48: 1/1] train loss: 0.291719 accuracy: 0.667400\n",
      "[49: 0/1] train loss: 0.286262 accuracy: 0.893900\n",
      "[49: 0/1] \u001b[94mtest\u001b[0m loss: 0.286015 accuracy: 0.908900\n",
      "[49: 1/1] train loss: 0.274439 accuracy: 0.680500\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.nepoch):\n",
    "    scheduler.step()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        points, target = data\n",
    "        points = points.transpose(2, 1)\n",
    "        points, target = points.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        classifier = classifier.train()\n",
    "        pred, trans, trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1)[:, 0] # -1\n",
    "        #print(pred.size(), target.size())\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        if opt.feature_transform:\n",
    "            loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "        print('[%d: %d/%d] train loss: %f accuracy: %f' % (epoch, i, num_batch, loss.item(), correct.item()/float(opt.batch_size * 2500)))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            j, data = next(enumerate(testdataloader, 0))\n",
    "            points, target = data\n",
    "            points = points.transpose(2, 1)\n",
    "            points, target = points.cuda(), target.cuda()\n",
    "            classifier = classifier.eval()\n",
    "            pred, _, _ = classifier(points)\n",
    "            pred = pred.view(-1, num_classes)\n",
    "            target = target.view(-1, 1)[:, 0] # -1\n",
    "            loss = F.nll_loss(pred, target)\n",
    "            pred_choice = pred.data.max(1)[1]\n",
    "            correct = pred_choice.eq(target.data).cpu().sum()\n",
    "            print('[%d: %d/%d] %s loss: %f accuracy: %f' % (epoch, i, num_batch, blue('test'), loss.item(), correct.item()/float(opt.batch_size * 2500)))\n",
    "\n",
    "    torch.save(classifier.state_dict(), '%s/seg_model_%s_%d.pth' % (opt.outf, opt.class_choice, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9adb493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mIOU for class Head: 0.5503428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## benchmark mIOU\n",
    "shape_ious = []\n",
    "for i,data in tqdm(enumerate(testdataloader, 0)):\n",
    "    points, target = data\n",
    "    points = points.transpose(2, 1)\n",
    "    points, target = points.cuda(), target.cuda()\n",
    "    classifier = classifier.eval()\n",
    "    pred, _, _ = classifier(points)\n",
    "    pred_choice = pred.data.max(2)[1]\n",
    "\n",
    "    pred_np = pred_choice.cpu().data.numpy()\n",
    "    target_np = target.cpu().data.numpy() - 1\n",
    "\n",
    "    for shape_idx in range(target_np.shape[0]):\n",
    "        parts = range(num_classes)#np.unique(target_np[shape_idx])\n",
    "        part_ious = []\n",
    "        for part in parts:\n",
    "            I = np.sum(np.logical_and(pred_np[shape_idx] == part, target_np[shape_idx] == part))\n",
    "            U = np.sum(np.logical_or(pred_np[shape_idx] == part, target_np[shape_idx] == part))\n",
    "            if U == 0:\n",
    "                iou = 1 #If the union of groundtruth and prediction points is empty, then count part IoU as 1\n",
    "            else:\n",
    "                iou = I / float(U)\n",
    "            part_ious.append(iou)\n",
    "        shape_ious.append(np.mean(part_ious))\n",
    "\n",
    "print(\"mIOU for class {}: {}\".format(opt.class_choice, np.mean(shape_ious)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190fc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
