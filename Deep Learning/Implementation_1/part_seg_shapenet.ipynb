{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9329100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import scipy.spatial.distance\n",
    "import math\n",
    "import random\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90bb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/trojan/skia_projects/3d_facial_segmentation/part_segmentation/pointnet/pointnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da74d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def read_pts(file):\n",
    "    verts = np.genfromtxt(file)\n",
    "    #return utils.cent_norm(verts)\n",
    "    return verts\n",
    "\n",
    "def read_seg(file):\n",
    "    verts = np.genfromtxt(file, dtype= (int))\n",
    "    return verts\n",
    "\n",
    "def sample_2000(pts, pts_cat):    \n",
    "    res1 = np.concatenate((pts,np.reshape(pts_cat, (pts_cat.shape[0], 1))), axis= 1)\n",
    "    res = np.asarray(random.choices(res1, weights=None, cum_weights=None, k=2000))\n",
    "    images = res[:, 0:3]\n",
    "    categories = res[:, 3]\n",
    "    categories-=np.ones(categories.shape)\n",
    "    return images, categories\n",
    "\n",
    "def read_data(file):\n",
    "    data = np.genfromtxt(file).astype(np.float64)\n",
    "    img = data[:, 0:3]\n",
    "    seg = data[:, -1].astype(np.int64)\n",
    "    return img, seg\n",
    "\n",
    "def Normalize(pointcloud):\n",
    "    norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
    "    norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "    return  norm_pointcloud\n",
    "\n",
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  rot_pointcloud\n",
    "    \n",
    "class Random_Noise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  noisy_pointcloud\n",
    "    \n",
    "    \n",
    "def rotation_z(pointcloud, theta):\n",
    "    rot_matrix = np.array([[ math.cos(theta), -math.sin(theta), 0],\n",
    "                               [ math.sin(theta),  math.cos(theta), 0],\n",
    "                               [0, 0, 1]])\n",
    "        \n",
    "    rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "    return  rot_pointcloud\n",
    "\n",
    "def random_noise(pointcloud):\n",
    "    noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "    noisy_pointcloud = pointcloud + noise\n",
    "    return  noisy_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42c1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, valid=False, transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.files = []\n",
    "        self.valid=valid\n",
    "\n",
    "        newdir = root_dir + '/datasets/airplane_part_seg/02691156/expert_verified/points_label/'\n",
    "        \n",
    "        for file in os.listdir(newdir):\n",
    "            o = {}\n",
    "            o['category'] = newdir + file\n",
    "            o['img_path'] = root_dir + '/datasets/airplane_part_seg/02691156/points/'+ file.replace('.seg', '.pts')\n",
    "            self.files.append(o)\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]['img_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(img_path, 'r') as f:\n",
    "            image1 = read_pts(f)\n",
    "        with open(category, 'r') as f:  \n",
    "            category1 = read_seg(f)\n",
    "        image2, category2 = sample_2000(image1, category1)\n",
    "        if not self.valid:\n",
    "            theta = random.random()*360\n",
    "            image2 = rotation_z(random_noise(image2), theta)\n",
    "        \n",
    "        return {'image': np.array(image2, dtype=\"float32\"), 'category': category2.astype(int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a8d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Dataset class created #########\n",
      "Number of images:  2690\n",
      "Sample image shape:  (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "dset = Data(root_dir , transform=None)\n",
    "train_num = int(len(dset) * 0.95)\n",
    "val_num = int(len(dset) *0.05)\n",
    "if int(len(dset)) - train_num -  val_num >0 :\n",
    "    train_num = train_num + 1\n",
    "elif int(len(dset)) - train_num -  val_num < 0:\n",
    "    train_num = train_num -1\n",
    "#train_dataset, val_dataset = random_split(dset, [3000, 118])\n",
    "train_dataset, val_dataset = random_split(dset, [train_num, val_num])\n",
    "val_dataset.valid=True\n",
    "\n",
    "print('######### Dataset class created #########')\n",
    "print('Number of images: ', len(dset))\n",
    "print('Sample image shape: ', dset[0]['image'].shape)\n",
    "#print('Sample image points categories', dset[0]['category'], end='\\n\\n')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(dset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ba3f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[-0.06971064,  0.08080515, -0.32695034],\n",
      "       [-0.17004186,  0.12170618,  0.07043187],\n",
      "       [ 0.03125751,  0.04869079, -0.05697311],\n",
      "       ...,\n",
      "       [ 0.16172117, -0.06551047, -0.00853489],\n",
      "       [-0.02024056,  0.05318477, -0.30802733],\n",
      "       [ 0.22926545, -0.10223312, -0.02601216]], dtype=float32), 'category': array([1, 0, 0, ..., 0, 1, 2])}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace0e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "        self.conv1 = nn.Conv1d(k,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "    def forward(self, input):\n",
    "    # input.shape == (bs,n,3)\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        flat = nn.Flatten(1)(pool)\n",
    "        xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "\n",
    "        #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=128)\n",
    "        self.fc1 = nn.Conv1d(3,64,1)\n",
    "        self.fc2 = nn.Conv1d(64,128,1) \n",
    "        self.fc3 = nn.Conv1d(128,128,1)\n",
    "        self.fc4 = nn.Conv1d(128,512,1)\n",
    "        self.fc5 = nn.Conv1d(512,2048,1)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(2048)\n",
    "\n",
    "    def forward(self, input):\n",
    "        n_pts = input.size()[2]\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "        outs = []\n",
    "\n",
    "        out1 = F.relu(self.bn1(self.fc1(xb)))\n",
    "        outs.append(out1)\n",
    "        out2 = F.relu(self.bn2(self.fc2(out1)))\n",
    "        outs.append(out2)\n",
    "        out3 = F.relu(self.bn3(self.fc3(out2)))\n",
    "        outs.append(out3)\n",
    "        matrix128x128 = self.feature_transform(out3)\n",
    "\n",
    "        out4 = torch.bmm(torch.transpose(out3,1,2), matrix128x128).transpose(1,2) \n",
    "        outs.append(out4)\n",
    "        out5 = F.relu(self.bn4(self.fc4(out4)))\n",
    "        outs.append(out5)\n",
    "\n",
    "        xb = self.bn5(self.fc5(out5))\n",
    "\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        out6 = nn.Flatten(1)(xb).repeat(n_pts,1,1).transpose(0,2).transpose(0,1)#.repeat(1, 1, n_pts)\n",
    "        outs.append(out6)\n",
    "\n",
    "\n",
    "        return outs, matrix3x3, matrix128x128\n",
    "\n",
    "\n",
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "\n",
    "        self.fc1 = nn.Conv1d(3008,256,1) \n",
    "        self.fc2 = nn.Conv1d(256,256,1) \n",
    "        self.fc3 = nn.Conv1d(256,128,1) \n",
    "        self.fc4 = nn.Conv1d(128,4,1) \n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.bn4 = nn.BatchNorm1d(4)\n",
    "        \n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        inputs, matrix3x3, matrix128x128 = self.transform(input)\n",
    "        stack = torch.cat(inputs,1)\n",
    "        \n",
    "        xb = F.relu(self.bn1(self.fc1(stack)))\n",
    "       \n",
    "        xb = F.relu(self.bn2(self.fc2(xb)))\n",
    "    \n",
    "        xb = F.relu(self.bn3(self.fc3(xb)))\n",
    "        \n",
    "        output = F.relu(self.bn4(self.fc4(xb)))\n",
    "        \n",
    "        return self.logsoftmax(output), matrix3x3, matrix128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd73f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313f38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNetSeg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "385cbe29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNetSeg(\n",
       "  (transform): Transform(\n",
       "    (input_transform): Tnet(\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (feature_transform): Tnet(\n",
       "      (conv1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=16384, bias=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "    (fc2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (fc3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    (fc4): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "    (fc5): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Conv1d(3008, 256, kernel_size=(1,), stride=(1,))\n",
       "  (fc2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "  (fc3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "  (fc4): Conv1d(128, 4, kernel_size=(1,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logsoftmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18779b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf16968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m128x128, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id128x128 = torch.eye(128, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id128x128=id128x128.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff128x128 = id128x128-torch.bmm(m128x128,m128x128.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff128x128)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14e83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['image'].to(device), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['image'].to(device), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0) * labels.size(1) ##\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100 * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            torch.save(pointnet.state_dict(), root_dir+\"/modelsSeg/\"+str(epoch)+\"_\"+str(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bd6bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.336\n",
      "[1,    20] loss: 1.211\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-add75b13e19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-297427e6a32a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, epochs, save)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpointnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9ac05daf28ad>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcategory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-43b2ca6c735c>\u001b[0m in \u001b[0;36mread_pts\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_pts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mverts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#return utils.cent_norm(verts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         rows = list(\n\u001b[1;32m   2139\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0;32m-> 2140\u001b[0;31m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         rows = list(\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         rows = list(\n\u001b[1;32m   2139\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0;32m-> 2140\u001b[0;31m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         rows = list(\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         rows = list(\n\u001b[0;32m-> 2139\u001b[0;31m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0m\u001b[1;32m   2140\u001b[0m                   for (i, conv) in enumerate(converters)]))\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pointnet2/lib/python3.7/site-packages/numpy/lib/_iotools.py\u001b[0m in \u001b[0;36m_loose_call\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_loose_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(pointnet, train_loader, val_loader,  save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad71f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
